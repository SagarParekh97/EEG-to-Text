{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06519bd5-1469-4754-ac0f-1727ec62bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"./EEG-to-Text-Project.git\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "sys.path\n",
    "\n",
    "custome_cache_dir = \"/home/linal20/transformers_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32133f65-fa93-4387-9b49-29815cc60388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custome_cache_dir = \"/home/linal20/transformers_cache\"\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pack_padded_sequence \n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BertTokenizer, BertLMHeadModel, BertConfig\n",
    "from data import ZuCo_dataset\n",
    "from model_sentiment import BaselineMLPSentence, BaselineLSTM\n",
    "\n",
    "# Function to calculate the accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()  \n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "560937de-e3e4-4497-a00b-df8cd030d9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "![Debug]using ALL\n",
      "[INFO]eeg type GD\n",
      "[INFO]using bands ['_t1', '_t2', '_a1', '_a2', '_b1', '_b2', '_g1', '_g2']\n",
      "[INFO]using device cuda:0\n",
      "[INFO]loading 1 task datasets\n",
      "[INFO]using subjects:  ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "train divider = 320\n",
      "dev divider = 360\n",
      "[INFO]initializing a train set...\n",
      "discard length zero instance:  Weiss and Speck never make a convincing case for the relevance of these two 20th-century footnotes.\n",
      "discard length zero instance:  Reassuring, retro uplifter.\n",
      "discard length zero instance:  Flaccid drama and exasperatingly slow journey.\n",
      "++ adding task to dataset, now we have: 3609\n",
      "[INFO]input tensor size: torch.Size([56, 840])\n",
      "\n",
      "[INFO]loading 1 task datasets\n",
      "[INFO]using subjects:  ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "train divider = 320\n",
      "dev divider = 360\n",
      "[INFO]initializing a dev set...\n",
      "discard length zero instance:  Gollum's `performance' is incredible!\n",
      "++ adding task to dataset, now we have: 467\n",
      "[INFO]input tensor size: torch.Size([56, 840])\n",
      "\n",
      "[INFO]train_set size:  3609\n",
      "[INFO]dev_set size:  467\n",
      "[INFO]Model: BaselineMLP\n",
      "=== start training  ===\n",
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 69.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1012\n",
      "train Acc: 0.3509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.1024\n",
      "dev Acc: 0.2940\n",
      "update best on dev checkpoint: ./checkpoints/eeg_sentiment/best/BaselineMLP_5e-05_b32_unique_sent_GD.pt\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1007\n",
      "train Acc: 0.3529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.1006\n",
      "dev Acc: 0.2940\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 68.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0998\n",
      "train Acc: 0.3529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0989\n",
      "dev Acc: 0.2898\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 68.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1001\n",
      "train Acc: 0.3550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 25.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0983\n",
      "dev Acc: 0.2856\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1008\n",
      "train Acc: 0.3399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0979\n",
      "dev Acc: 0.2836\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0987\n",
      "train Acc: 0.3469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0976\n",
      "dev Acc: 0.2856\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 66.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0995\n",
      "train Acc: 0.3374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0969\n",
      "dev Acc: 0.2794\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1008\n",
      "train Acc: 0.3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0961\n",
      "dev Acc: 0.2815\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1000\n",
      "train Acc: 0.3429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0967\n",
      "dev Acc: 0.2877\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 66.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0995\n",
      "train Acc: 0.3407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0960\n",
      "dev Acc: 0.2877\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0991\n",
      "train Acc: 0.3394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0959\n",
      "dev Acc: 0.2856\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0973\n",
      "train Acc: 0.3511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0959\n",
      "dev Acc: 0.2856\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0987\n",
      "train Acc: 0.3522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 23.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0960\n",
      "dev Acc: 0.2919\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0982\n",
      "train Acc: 0.3434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0958\n",
      "dev Acc: 0.2940\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 68.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0997\n",
      "train Acc: 0.3358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0959\n",
      "dev Acc: 0.2981\n",
      "update best on dev checkpoint: ./checkpoints/eeg_sentiment/best/BaselineMLP_5e-05_b32_unique_sent_GD.pt\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0976\n",
      "train Acc: 0.3546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0957\n",
      "dev Acc: 0.3002\n",
      "update best on dev checkpoint: ./checkpoints/eeg_sentiment/best/BaselineMLP_5e-05_b32_unique_sent_GD.pt\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0984\n",
      "train Acc: 0.3546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0955\n",
      "dev Acc: 0.3009\n",
      "update best on dev checkpoint: ./checkpoints/eeg_sentiment/best/BaselineMLP_5e-05_b32_unique_sent_GD.pt\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 67.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0988\n",
      "train Acc: 0.3397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0955\n",
      "dev Acc: 0.3030\n",
      "update best on dev checkpoint: ./checkpoints/eeg_sentiment/best/BaselineMLP_5e-05_b32_unique_sent_GD.pt\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 66.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0979\n",
      "train Acc: 0.3480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0952\n",
      "dev Acc: 0.3030\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:01<00:00, 66.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0988\n",
      "train Acc: 0.3391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 24.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 1.0950\n",
      "dev Acc: 0.3050\n",
      "update best on dev checkpoint: ./checkpoints/eeg_sentiment/best/BaselineMLP_5e-05_b32_unique_sent_GD.pt\n",
      "\n",
      "Training complete in 0m 46s\n",
      "Best val loss: 1.094992\n",
      "Best val acc: 0.305044\n",
      "update last checkpoint: ./checkpoints/eeg_sentiment/last/BaselineMLP_5e-05_b32_unique_sent_GD.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##### training sentiment baseline models #####\n",
    "def train_model(dataloaders, device, model, criterion, optimizer, scheduler, num_epochs=25, checkpoint_path_best = './checkpoints2/eeg_sentiment/best/test.pt', checkpoint_path_last = './checkpoints2/eeg_sentiment/last/test.pt'):\n",
    "    since = time.time()\n",
    "      \n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100000000000\n",
    "    best_acc = 0.0\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'dev']:\n",
    "            total_accuracy = 0.0\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for input_word_eeg_features, seq_lens, input_masks, input_mask_invert, target_ids, target_mask, sentiment_labels, sent_level_EEG in tqdm(dataloaders[phase]):\n",
    "                \n",
    "                input_word_eeg_features = input_word_eeg_features.to(device).float()\n",
    "                sent_level_EEG = sent_level_EEG.to(device)\n",
    "                input_masks = input_masks.to(device)\n",
    "                sentiment_labels = sentiment_labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if isinstance(model, BaselineMLPSentence):\n",
    "                    # forward\n",
    "                    logits = model(sent_level_EEG) # before softmax\n",
    "                    # calculate loss\n",
    "                    loss = criterion(logits, sentiment_labels)\n",
    "                \n",
    "                elif isinstance(model, BaselineLSTM):\n",
    "                    x_packed = pack_padded_sequence(input_word_eeg_features, seq_lens, batch_first=True, enforce_sorted=False)\n",
    "                    logits = model(x_packed)\n",
    "                    # calculate loss\n",
    "                    loss = criterion(logits, sentiment_labels)\n",
    "                \n",
    "\n",
    "                # backward & optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    # with torch.autograd.detect_anomaly():\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # calculate accuracy\n",
    "                preds_cpu = logits.detach().cpu().numpy()\n",
    "                label_cpu = sentiment_labels.cpu().numpy()\n",
    "\n",
    "                total_accuracy += flat_accuracy(preds_cpu, label_cpu)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * sent_level_EEG.size()[0] # batch loss\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = total_accuracy / len(dataloaders[phase])\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            print('{} Acc: {:.4f}'.format(phase, epoch_acc))\n",
    "         \n",
    "            if phase == 'dev' and (epoch_acc > best_acc):\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_weights = copy.deepcopy(model.state_dict())\n",
    "                '''save checkpoint'''\n",
    "                torch.save(model.state_dict(), checkpoint_path_best)\n",
    "                print(f'update best on dev checkpoint: {checkpoint_path_best}')\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    print('Best val acc: {:4f}'.format(best_acc))\n",
    "    torch.save(model.state_dict(), checkpoint_path_last)\n",
    "    print(f'update last checkpoint: {checkpoint_path_last}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_weights)\n",
    "    return model\n",
    "# import os\n",
    "# os.environ[\"TRANSFORMERS_CACHE\"] = \"/home/linal20/NLP_final_project\"\n",
    "# python3 train_sentiment_baseline.py --model_name BaselineMLP --num_epoch 20 -lr 0.00005 -b 32 -s ./checkpoints/eeg_sentiment -cuda cuda:0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    #set param\n",
    "    num_epochs = 20\n",
    "    step_lr = 0.00005\n",
    "    dataset_setting = 'unique_sent'\n",
    "\n",
    "    subject_choice = 'ALL'\n",
    "    print(f'![Debug]using {subject_choice}')\n",
    "    eeg_type_choice = 'GD'\n",
    "    print(f'[INFO]eeg type {eeg_type_choice}')\n",
    "    bands_choice = ['_t1','_t2','_a1','_a2','_b1','_b2','_g1','_g2'] \n",
    "    print(f'[INFO]using bands {bands_choice}')\n",
    "    \n",
    "    # model name\n",
    "    model_name = 'BaselineMLP'\n",
    "    # model_name = 'BaselineLSTM'\n",
    "\n",
    "\n",
    "    batch_size = 32\n",
    "    save_path = './checkpoints/eeg_sentiment'\n",
    "    save_name = f'{model_name}_{step_lr}_b{batch_size}_{dataset_setting}_{eeg_type_choice}'\n",
    "\n",
    "    if model_name == 'BaselineLSTM':\n",
    "        num_layers = 4\n",
    "        save_name = f'{model_name}_numLayers-{num_layers}_{step_lr}_b{batch_size}_{dataset_setting}_{eeg_type_choice}'\n",
    "\n",
    "    output_checkpoint_name_best = save_path + f'/best/{save_name}.pt' \n",
    "    output_checkpoint_name_last = save_path + f'/last/{save_name}.pt' \n",
    "\n",
    "\n",
    "    \n",
    "    # random seeds \n",
    "    seed_val = 312\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "\n",
    "    # set up device\n",
    "    # use cuda\n",
    "    if torch.cuda.is_available():  \n",
    "        # dev = args['cuda']\n",
    "        dev = 'cuda:0'\n",
    "    else:  \n",
    "        dev = \"cpu\"\n",
    "    # CUDA_VISIBLE_DEVICES=0,1,2,3  \n",
    "    device = torch.device(dev)\n",
    "    print(f'[INFO]using device {dev}')\n",
    "\n",
    "\n",
    "    # load pickle\n",
    "    whole_dataset_dict = []\n",
    "    # dataset_path_task1 = './dataset/ZuCo/task1-SR/pickle/task1-SR-dataset.pickle' \n",
    "    dataset_path_task1 ='./dataset/processed/Task1_SR_processed.pickle'\n",
    "    with open(dataset_path_task1, 'rb') as handle:\n",
    "        whole_dataset_dict.append(pickle.load(handle))\n",
    "    \n",
    "    # tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased',cache_dir=custome_cache_dir )\n",
    "\n",
    "    # set up dataloader \n",
    "    # train dataset\n",
    "    train_set = ZuCo_dataset(whole_dataset_dict, 'train', tokenizer, subject = subject_choice, eeg_type = eeg_type_choice, bands = bands_choice, setting = dataset_setting)\n",
    "    # dev dataset\n",
    "    dev_set = ZuCo_dataset(whole_dataset_dict, 'dev', tokenizer, subject = subject_choice, eeg_type = eeg_type_choice, bands = bands_choice, setting = dataset_setting)\n",
    "\n",
    "    dataset_sizes = {'train': len(train_set), 'dev': len(dev_set)}\n",
    "    print('[INFO]train_set size: ', len(train_set))\n",
    "    print('[INFO]dev_set size: ', len(dev_set))\n",
    "    \n",
    "    # train dataloader\n",
    "    train_dataloader = DataLoader(train_set, batch_size = batch_size, shuffle=True, num_workers=4)\n",
    "    # dev dataloader\n",
    "    val_dataloader = DataLoader(dev_set, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "    # dataloaders\n",
    "    dataloaders = {'train':train_dataloader, 'dev':val_dataloader}\n",
    "\n",
    "    ''' set up model '''\n",
    "    if model_name == 'BaselineMLP':\n",
    "        print('[INFO]Model: BaselineMLP')\n",
    "        model = BaselineMLPSentence(input_dim = 105*len(bands_choice), hidden_dim = 128, output_dim = 3)\n",
    "    elif model_name == 'BaselineLSTM':\n",
    "        print('[INFO]Model: BaselineLSTM')\n",
    "        model = BaselineLSTM(input_dim = 105*len(bands_choice), hidden_dim = 256, output_dim = 3, num_layers = num_layers)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    ### training loop ### \n",
    "\n",
    "    # set up optimizer and scheduler\n",
    "    optimizer_step1 = optim.SGD(model.parameters(), lr=step_lr, momentum=0.9)\n",
    "    exp_lr_scheduler_step1 = lr_scheduler.StepLR(optimizer_step1, step_size=20, gamma=0.5)\n",
    "\n",
    "    # loss function \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print('=== start training  ===')\n",
    "    # return best loss model from step1 training\n",
    "    model = train_model(dataloaders, device, model, criterion, optimizer_step1, exp_lr_scheduler_step1, num_epochs=num_epochs, checkpoint_path_best = output_checkpoint_name_best, checkpoint_path_last = output_checkpoint_name_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248dbc1-d903-4aca-ad12-83ccc0c8279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] eval BaselineMLP\n",
      "[INFO] loading baseline: ./checkpoints/eeg_sentiment/best/BaselineMLP_5e-05_b32_unique_sent_GD.pt\n",
      "![Debug]using ALL\n",
      "[INFO]eeg type GD\n",
      "[INFO]using bands ['_t1', '_t2', '_a1', '_a2', '_b1', '_b2', '_g1', '_g2']\n",
      "[INFO]using device cuda:1\n",
      "[INFO]using Bert tokenizer\n",
      "[INFO]Model: BaselineMLP\n",
      "[INFO]loading 1 task datasets\n",
      "[INFO]using subjects:  ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "train divider = 320\n",
      "dev divider = 360\n",
      "[INFO]initializing a test set...\n",
      "++ adding task to dataset, now we have: 456\n",
      "[INFO]input tensor size: torch.Size([56, 840])\n",
      "\n",
      "[INFO]test_set size:  456\n",
      "=== start evaluating ===\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "###### evaluate sentiment baseline models #####\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pack_padded_sequence \n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig, BartForSequenceClassification, BertTokenizer, BertConfig, BertForSequenceClassification, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from data import ZuCo_dataset\n",
    "from model_sentiment import BaselineMLPSentence, BaselineLSTM, FineTunePretrainedTwoStep, ZeroShotSentimentDiscovery, JointBrainTranslatorSentimentClassifier\n",
    "from model_decoding import BrainTranslator, BrainTranslatorNaive\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from config import get_config\n",
    "\n",
    "customed_cache_dir = \"/home/linal20/transformers_cache\"\n",
    "\n",
    "# Function to calculate the accuracy \n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()  \n",
    "    \n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(dataloaders, device, model, criterion, optimizer, scheduler, num_epochs=25, tokenizer = BartTokenizer.from_pretrained('facebook/bart-large',cache_dir= customed_cache_dir)):\n",
    "\n",
    "    def logits2PredString(logits, tokenizer):\n",
    "        probs = logits[0].softmax(dim = 1)\n",
    "        values, predictions = probs.topk(1)\n",
    "        predictions = torch.squeeze(predictions)\n",
    "        predict_string = tokenizer.decode(predictions)\n",
    "        return predict_string\n",
    "    \n",
    "    since = time.time()\n",
    "      \n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100000000000\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    total_pred_labels = np.array([])\n",
    "    total_true_labels = np.array([])\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "    \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['test']:\n",
    "            total_accuracy = 0.0\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "    \n",
    "            running_loss = 0.0\n",
    "    \n",
    "            # Iterate over data.\n",
    "            for input_word_eeg_features, seq_lens, input_masks, input_mask_invert, target_ids, target_mask, sentiment_labels, sent_level_EEG in dataloaders[phase]:\n",
    "                \n",
    "                input_word_eeg_features = input_word_eeg_features.to(device).float()\n",
    "                input_masks = input_masks.to(device)\n",
    "                input_mask_invert = input_mask_invert.to(device)\n",
    "    \n",
    "                sent_level_EEG = sent_level_EEG.to(device)\n",
    "                sentiment_labels = sentiment_labels.to(device)\n",
    "    \n",
    "                target_ids = target_ids.to(device)\n",
    "                target_mask = target_mask.to(device)\n",
    "    \n",
    "                ## forward ###################\n",
    "                if isinstance(model, BaselineMLPSentence):\n",
    "                    logits = model(sent_level_EEG) # before softmax\n",
    "                    # calculate loss\n",
    "                    loss = criterion(logits, sentiment_labels)\n",
    "    \n",
    "                elif isinstance(model, BaselineLSTM):\n",
    "                    x_packed = pack_padded_sequence(input_word_eeg_features, seq_lens, batch_first=True, enforce_sorted=False)\n",
    "                    logits = model(x_packed)\n",
    "                    # calculate loss\n",
    "                    loss = criterion(logits, sentiment_labels)\n",
    "    \n",
    "          \n",
    "    \n",
    "                # backward and optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    # with torch.autograd.detect_anomaly():\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "    \n",
    "                # calculate accuracy\n",
    "                preds_cpu = logits.detach().cpu().numpy()\n",
    "                label_cpu = sentiment_labels.cpu().numpy()\n",
    "    \n",
    "                total_accuracy += flat_accuracy(preds_cpu, label_cpu)\n",
    "                \n",
    "                # add to total pred and label array, for cal F1, precision, recall\n",
    "                pred_flat = np.argmax(preds_cpu, axis=1).flatten()\n",
    "                labels_flat = label_cpu.flatten()\n",
    "    \n",
    "                total_pred_labels = np.concatenate((total_pred_labels,pred_flat))\n",
    "                total_true_labels = np.concatenate((total_true_labels,labels_flat))\n",
    "                \n",
    "    \n",
    "                # statistics\n",
    "                running_loss += loss.item() * sent_level_EEG.size()[0] # batch loss               \n",
    "    \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "    \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = total_accuracy / len(dataloaders[phase])\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            print('{} Acc: {:.4f}'.format(phase, epoch_acc))\n",
    "    \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test loss: {:4f}'.format(best_loss))\n",
    "    print('Best test acc: {:4f}'.format(best_acc))\n",
    "    print()\n",
    "    print('test sample num:', len(total_pred_labels))\n",
    "    print('total preds:',total_pred_labels)\n",
    "    print('total truth:',total_true_labels)\n",
    "    print('sklearn macro: precision, recall, F1:')\n",
    "    print(precision_recall_fscore_support(total_true_labels, total_pred_labels, average='macro'))\n",
    "    print()\n",
    "    print('sklearn micro: precision, recall, F1:')\n",
    "    print(precision_recall_fscore_support(total_true_labels, total_pred_labels, average='micro'))\n",
    "    print()\n",
    "    print('sklearn accuracy:')\n",
    "    print(accuracy_score(total_true_labels,total_pred_labels))\n",
    "    print()\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # set param\n",
    "    num_epochs = 25\n",
    "    \n",
    "    dataset_setting = 'unique_sent'\n",
    "    \n",
    "    # model name\n",
    "    model_name = 'BaselineMLP'\n",
    "    # model_name = 'BaselineLSTM'\n",
    "    \n",
    "    print(f'[INFO] eval {model_name}')\n",
    "    if model_name == 'ZeroShotSentimentDiscovery':\n",
    "     \n",
    "        # generator\n",
    "        decoder_name = 'BrainTranslator'\n",
    "        decoder_checkpoint= './checkpoints/decoding/best/task1_finetune_BrainTranslator_skipstep1_b32_20_30_5e-05_5e-07_unique_sent.pt' \n",
    "        print(f'[INFO] using decoder: {decoder_name}')\n",
    "    \n",
    "       # classifier\n",
    "        # pretrain_Bert, pretrain_RoBerta, pretrain_Bart\n",
    "        classifier_name = 'pretrain_Bert'\n",
    "        classifier_checkpoint = './checkpoints/text_sentiment_classifier/best/Textbased_StanfordSentitmentTreeband_pretrain_Bert_b32_20_0.0001.pt'\n",
    "        # classifier_checkpoint  = f'./checkpoints/text_sentiment_classifier/best/Textbased_StanfordSentitmentTreeband_{model_name}_b32_20_0.0001.pt'\n",
    "        print(f'[INFO] using classifier: {classifier_name}')\n",
    "    else:\n",
    "        # checkpoint_path = args['checkpoint_path']\n",
    "        # checkpoint_path = './checkpoints/text_sentiment_classifier/best/Textbased_StanfordSentitmentTreeband_pretrain_Bart_b32_20_0.0001.pt'\n",
    "        if model_name == 'BaselineLSTM':\n",
    "            num_layers = 4\n",
    "            checkpoint_path = f'./checkpoints/eeg_sentiment/best/{model_name}_numLayers-{num_layers}_{step_lr}_b{batch_size}_{dataset_setting}_{eeg_type_choice}.pt'\n",
    "        else: \n",
    "            checkpoint_path = f'./checkpoints/eeg_sentiment/best/{model_name}_{step_lr}_b{batch_size}_{dataset_setting}_{eeg_type_choice}.pt'\n",
    "    \n",
    "        \n",
    "        print('[INFO] loading baseline:', checkpoint_path)\n",
    "    \n",
    "    \n",
    "    batch_size = 32\n",
    "    \n",
    "    \n",
    "    subject_choice = 'ALL'\n",
    "    print(f'![Debug]using {subject_choice}')\n",
    "    eeg_type_choice = 'GD'\n",
    "    print(f'[INFO]eeg type {eeg_type_choice}')\n",
    "    bands_choice = ['_t1','_t2','_a1','_a2','_b1','_b2','_g1','_g2'] \n",
    "    print(f'[INFO]using bands {bands_choice}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # random seeds\n",
    "    seed_val = 312\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "    \n",
    "    \n",
    "    # device\n",
    "    # use cuda\n",
    "    if torch.cuda.is_available():  \n",
    "        # dev = args['cuda']\n",
    "         dev = 'cuda:1'\n",
    "    else:  \n",
    "        dev = \"cpu\"\n",
    "    # CUDA_VISIBLE_DEVICES=0,1,2,3  \n",
    "    device = torch.device(dev)\n",
    "    print(f'[INFO]using device {dev}')\n",
    "    \n",
    "    \n",
    "    #  load Task1_SR_processed.pickle\n",
    "    whole_dataset_dict = []\n",
    "    # dataset_path_task1 = './dataset/ZuCo/task1-SR/pickle/Task1_SR_processed.pickle'\n",
    "    dataset_path_task1 ='./dataset/processed/Task1_SR_processed.pickle'\n",
    "    with open(dataset_path_task1, 'rb') as handle:\n",
    "        whole_dataset_dict.append(pickle.load(handle))\n",
    "    \n",
    "    # tokenizer\n",
    "    if model_name in ['BaselineMLP','BaselineLSTM', 'NaiveFinetuneBert', 'FinetunedBertOnText']:\n",
    "        print('[INFO]using Bert tokenizer')\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-cased',cache_dir=\"/home/linal20/NLP_final_project\")\n",
    "    \n",
    "    # model \n",
    "    if model_name == 'BaselineMLP':\n",
    "        print('[INFO]Model: BaselineMLP')\n",
    "        model = BaselineMLPSentence(input_dim = 840, hidden_dim = 128, output_dim = 3)\n",
    "    elif model_name == 'BaselineLSTM':\n",
    "        print('[INFO]Model: BaselineLSTM')\n",
    "        model = BaselineLSTM(input_dim = 840, hidden_dim = 256, output_dim = 3, num_layers = 4)\n",
    "    \n",
    "    \n",
    "    if model_name != 'ZeroShotSentimentDiscovery':\n",
    "        # load model and send to device\n",
    "        model.load_state_dict(torch.load(checkpoint_path))\n",
    "        model.to(device)\n",
    "    \n",
    "    #  dataloader '''\n",
    "    # test dataset\n",
    "    test_set = ZuCo_dataset(whole_dataset_dict, 'test', tokenizer, subject = subject_choice, eeg_type = eeg_type_choice, bands = bands_choice, setting = 'unique_sent')\n",
    "    \n",
    "    dataset_sizes = {'test': len(test_set)}\n",
    "    # print('[INFO]train_set size: ', len(train_set))\n",
    "    print('[INFO]test_set size: ', len(test_set))\n",
    "    \n",
    "    test_dataloader = DataLoader(test_set, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "    # dataloaders\n",
    "    dataloaders = {'test':test_dataloader}\n",
    "    \n",
    "    # optimizer and scheduler\n",
    "    optimizer_step1 = None\n",
    "    exp_lr_scheduler_step1 = None\n",
    "    \n",
    "    # loss function \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print('=== start evaluating ===')\n",
    "    # return best loss model from step1 training\n",
    "    model = eval_model(dataloaders, device, model, criterion, optimizer_step1, exp_lr_scheduler_step1, num_epochs=25, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ef157-696d-4d10-8d04-a514277bfeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch2)",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
